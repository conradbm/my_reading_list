%% This BibTeX bibliography file was created using BibDesk.
%% http://bibdesk.sourceforge.net/

%% Created for Tom Cook at 2017-04-27 12:56:42 -0500 


%% Saved with string encoding Unicode (UTF-8) 



@article{li:20172b,
	Abstract = {To obtain uncertainty estimates with real-world Bayesian deep learning models, practical inference approximations are needed. Dropout variational inference (VI) for example has been used for machine vision and medical applications, but VI can severely underestimates model uncertainty. Alpha-divergences are alternative divergences to VI's KL objective, which are able to avoid VI's uncertainty underestimation. But these are hard to use in practice: existing techniques can only use Gaussian approximating distributions, and require existing models to be changed radically, thus are of limited use for practitioners. We propose a re-parametrisation of the alpha-divergence objectives, deriving a simple inference technique which, together with dropout, can be easily implemented with existing models by simply changing the loss of the model. We demonstrate improved uncertainty estimates and accuracy compared to VI in dropout networks. We study our model's epistemic uncertainty far away from the data using adversarial images, showing that these can be distinguished from non-adversarial images by examining our model's uncertainty.},
	Author = {Yingzhen Li and Yarin Gal},
	Date-Added = {2017-04-27 17:56:38 +0000},
	Date-Modified = {2017-04-27 17:56:38 +0000},
	Eprint = {1703.02914},
	Month = {03},
	Title = {Dropout Inference in Bayesian Neural Networks with Alpha-divergences},
	Url = {https://arxiv.org/abs/1703.02914},
	Year = {2017},
	Bdsk-Url-1 = {https://arxiv.org/abs/1703.02914}}

@article{li:20172a,
	Abstract = {We give an overview of recent exciting achievements of deep reinforcement learning (RL). We start with background of deep learning and reinforcement learning, as well as introduction of testbeds. Next we discuss Deep Q-Network (DQN) and its extensions, asynchronous methods, policy optimization, reward, and planning. After that, we talk about attention and memory, unsupervised learning, and learning to learn. Then we discuss various applications of RL, including games, in particular, AlphaGo, robotics, spoken dialogue systems (a.k.a. chatbot), machine translation, text sequence prediction, neural architecture design, personalized web services, healthcare, finance, and music generation. We mention topics/papers not reviewed yet. After listing a collection of RL resources, we close with discussions.},
	Author = {Yuxi Li},
	Date-Added = {2017-04-27 17:55:47 +0000},
	Date-Modified = {2017-04-27 17:55:47 +0000},
	Eprint = {1701.07274},
	Month = {01},
	Title = {Deep Reinforcement Learning: An Overview},
	Url = {https://arxiv.org/abs/1701.07274},
	Year = {2017},
	Bdsk-Url-1 = {https://arxiv.org/abs/1701.07274}}

@book{rasmussen:20062a,
	Author = {Carl Edward Rasmussen and Christopher K. I. Williams},
	Date-Added = {2017-04-27 17:53:50 +0000},
	Date-Modified = {2017-04-27 17:54:39 +0000},
	Publisher = {MIT Press},
	Title = {Gaussian Processes for Machine Learning},
	Url = {http://www.gaussianprocess.org/gpml/chapters/},
	Year = {2006}}

@electronic{olah:2a,
	Author = {Christopher Olah},
	Date-Added = {2017-04-27 17:52:22 +0000},
	Date-Modified = {2017-04-27 17:53:42 +0000},
	Title = {Understanding LSTM Networks},
	Url = {http://colah.github.io/posts/2015-08-Understanding-LSTMs/},
	Urldate = {2015}}

@electronic{karpathy:2a,
	Author = {Andrej Karpathy},
	Date-Added = {2017-04-27 17:51:34 +0000},
	Date-Modified = {2017-04-27 17:52:08 +0000},
	Title = {The Unreasonable Effectiveness of Recurrent Neural Networks},
	Url = {http://karpathy.github.io/2015/05/21/rnn-effectiveness/},
	Urldate = {May 21, 2015}}

@article{qi:20082a,
	Author = {Qi, Min and Zhang, G Peter},
	Date-Added = {2017-04-27 17:50:50 +0000},
	Date-Modified = {2017-04-27 17:50:51 +0000},
	Journal = {IEEE Transactions on neural networks},
	Number = {5},
	Pages = {808--816},
	Publisher = {IEEE},
	Title = {Trend time--series modeling and forecasting with neural networks},
	Volume = {19},
	Year = {2008}}

@electronic{ruder:2a,
	Author = {Sebastian Ruder},
	Date-Added = {2017-04-27 17:49:27 +0000},
	Date-Modified = {2017-04-27 17:50:10 +0000},
	Title = {An overview of gradient descent optimization algorithms},
	Url = {http://sebastianruder.com/optimizing-gradient-descent/},
	Urldate = {2017}}

@electronic{koller:2a,
	Annote = {https://www.youtube.com/playlist?list=PL50E6E80E8525B59C
https://www.coursera.org/learn/probabilistic-graphical-models
},
	Author = {Daphne Koller},
	Date-Added = {2017-04-27 17:44:17 +0000},
	Date-Modified = {2017-04-27 17:48:55 +0000},
	Howpublished = {web course},
	Title = {probabilistic graph models},
	Url = {http://openclassroom.stanford.edu/MainFolder/CoursePage.php?course=ProbabilisticGraphicalModels},
	Urldate = {2017}}

@article{nielsen:20152a,
	Author = {Nielsen, Michael A},
	Date-Added = {2017-03-20 14:33:15 +0000},
	Date-Modified = {2017-03-20 14:33:18 +0000},
	Journal = {URL: http://neuralnetworksanddeeplearning. com/.(visited: 01.11. 2014)},
	Title = {Neural networks and deep learning},
	Year = {2015}}

@inproceedings{gal:20152b,
	Author = {Gal, Yarin and Ghahramani, Zoubin},
	Booktitle = {Deep Learning Workshop, ICML},
	Date-Added = {2017-03-14 19:03:26 +0000},
	Date-Modified = {2017-03-14 19:04:27 +0000},
	Title = {Dropout as a Bayesian approximation: Insights and applications},
	Url = {http://ece.duke.edu/~lcarin/Chunyuan1.15.2016.pdf , https://arxiv.org/abs/1506.02157},
	Year = {2015},
	Bdsk-Url-1 = {http://ece.duke.edu/~lcarin/Chunyuan1.15.2016.pdf%20,%20https://arxiv.org/abs/1506.02157}}

@article{gal:20152a,
	Abstract = {Deep learning tools have gained tremendous attention in applied machine learning. However such tools for regression and classification do not capture model uncertainty. In comparison, Bayesian models offer a mathematically grounded framework to reason about model uncertainty, but usually come with a prohibitive computational cost. In this paper we develop a new theoretical framework casting dropout training in deep neural networks (NNs) as approximate Bayesian inference in deep Gaussian processes. A direct result of this theory gives us tools to model uncertainty with dropout NNs -- extracting information from existing models that has been thrown away so far. This mitigates the problem of representing uncertainty in deep learning without sacrificing either computational complexity or test accuracy. We perform an extensive study of the properties of dropout's uncertainty. Various network architectures and non-linearities are assessed on tasks of regression and classification, using MNIST as an example. We show a considerable improvement in predictive log-likelihood and RMSE compared to existing state-of-the-art methods, and finish by using dropout's uncertainty in deep reinforcement learning.},
	Author = {Yarin Gal and Zoubin Ghahramani},
	Date-Added = {2017-03-14 19:00:02 +0000},
	Date-Modified = {2017-03-14 19:00:02 +0000},
	Eprint = {1506.02142},
	Month = {06},
	Title = {Dropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning},
	Url = {https://arxiv.org/abs/1506.02142},
	Year = {2015},
	Bdsk-Url-1 = {https://arxiv.org/abs/1506.02142}}

@phdthesis{Gal2016Uncertainty,
	Author = {Gal, Yarin},
	Date-Added = {2017-03-02 19:28:32 +0000},
	Date-Modified = {2017-03-02 19:28:32 +0000},
	School = {University of Cambridge},
	Title = {Uncertainty in Deep Learning},
	Year = {2016}}

@article{zhou:20172a,
	Abstract = {In this paper, we propose gcForest, a decision tree ensemble approach with performance highly competitive to deep neural networks. In contrast to deep neural networks which require great effort in hyper-parameter tuning, gcForest is much easier to train. Actually, even when gcForest is applied to different data from different domains, excellent performance can be achieved by almost same settings of hyper-parameters. The training process of gcForest is efficient and scalable. In our experiments its training time running on a PC is comparable to that of deep neural networks running with GPU facilities, and the efficiency advantage may be more apparent because gcForest is naturally apt to parallel implementation. Furthermore, in contrast to deep neural networks which require large-scale training data, gcForest can work well even when there are only small-scale training data. Moreover, as a tree-based approach, gcForest should be easier for theoretical analysis than deep neural networks.},
	Author = {Zhi-Hua Zhou and Ji Feng},
	Date-Added = {2017-03-02 19:27:59 +0000},
	Date-Modified = {2017-03-02 19:27:59 +0000},
	Eprint = {1702.08835},
	Month = {02},
	Title = {Deep Forest: Towards An Alternative to Deep Neural Networks},
	Url = {https://arxiv.org/abs/1702.08835},
	Year = {2017},
	Bdsk-Url-1 = {https://arxiv.org/abs/1702.08835}}

@article{wang:20172a,
	Abstract = {This paper is a review of the evolutionary history of deep learning models. It covers from the genesis of neural networks when associationism modeling of the brain is studied, to the models that dominate the last decade of research in deep learning like convolutional neural networks, deep belief networks, and recurrent neural networks, and extends to popular recent models like variational autoencoder and generative adversarial nets. In addition to a review of these models, this paper primarily focuses on the precedents of the models above, examining how the initial ideas are assembled to construct the early models and how these preliminary models are developed into their current forms. Many of these evolutionary paths last more than half a century and have a diversity of directions. For example, CNN is built on prior knowledge of biological vision system; DBN is evolved from a trade-off of modeling power and computation complexity of graphical models and many nowadays models are neural counterparts of ancient linear models. This paper reviews these evolutionary paths and offers a concise thought flow of how these models are developed, and aims to provide a thorough background for deep learning. More importantly, along with the path, this paper summarizes the gist behind these milestones and proposes many directions to guide the future research of deep learning.},
	Author = {Haohan Wang and Bhiksha Raj},
	Date-Added = {2017-03-02 19:27:42 +0000},
	Date-Modified = {2017-03-02 19:27:42 +0000},
	Eprint = {1702.07800},
	Month = {02},
	Title = {On the Origin of Deep Learning},
	Url = {https://arxiv.org/abs/1702.07800},
	Year = {2017},
	Bdsk-Url-1 = {https://arxiv.org/abs/1702.07800}}

@article{parisotto:20172a,
	Abstract = {A critical component to enabling intelligent reasoning in partially observable environments is memory. Despite this importance, Deep Reinforcement Learning (DRL) agents have so far used relatively simple memory architectures, with the main methods to overcome partial observability being either a temporal convolution over the past k frames or an LSTM layer. More recent work (Oh et al., 2016) has went beyond these architectures by using memory networks which can allow more sophisticated addressing schemes over the past k frames. But even these architectures are unsatisfactory due to the reason that they are limited to only remembering information from the last k frames. In this paper, we develop a memory system with an adaptable write operator that is customized to the sorts of 3D environments that DRL agents typically interact with. This architecture, called the Neural Map, uses a spatially structured 2D memory image to learn to store arbitrary information about the environment over long time lags. We demonstrate empirically that the Neural Map surpasses previous DRL memories on a set of challenging 2D and 3D maze environments and show that it is capable of generalizing to environments that were not seen during training.},
	Author = {Emilio Parisotto and Ruslan Salakhutdinov},
	Date-Added = {2017-03-02 19:27:34 +0000},
	Date-Modified = {2017-03-02 19:27:34 +0000},
	Eprint = {1702.08360},
	Month = {02},
	Title = {Neural Map: Structured Memory for Deep Reinforcement Learning},
	Url = {https://arxiv.org/abs/1702.08360},
	Year = {2017},
	Bdsk-Url-1 = {https://arxiv.org/abs/1702.08360}}

@article{mao:20162a,
	Abstract = {Unsupervised learning with generative adversarial networks (GANs) has proven hugely successful. Regular GANs hypothesize the discriminator as a classifier with the sigmoid cross entropy loss function. This loss function, however, may lead to the vanishing gradient problem during the learning process. To overcome such problem, here we propose the Least Squares Generative Adversarial Networks (LSGANs) that adopt the least squares loss function for the discriminator. We show that minimizing the objective function of LSGAN yields minimizing the Pearson $\chi^2$ divergence. There are two benefits of LSGANs over regular GANs. First, LSGANs are able to generate higher quality images than regular GANs. Second, LSGANs performs more stable during the learning process. We evaluate the LSGANs on five scene datasets and the experimental results demonstrate that the generated images by LSGANs look more realistic than the ones generated by regular GANs. We also conduct two comparison experiments between LSGANs and regular GANs to illustrate the stability of LSGANs.},
	Author = {Xudong Mao and Qing Li and Haoran Xie and Raymond Y.K. Lau and Zhen Wang},
	Date-Added = {2017-03-02 19:27:27 +0000},
	Date-Modified = {2017-03-02 19:27:27 +0000},
	Eprint = {1611.04076},
	Month = {11},
	Title = {Least Squares Generative Adversarial Networks},
	Url = {https://arxiv.org/abs/1611.04076},
	Year = {2016},
	Bdsk-Url-1 = {https://arxiv.org/abs/1611.04076}}

@article{nachum:20172a,
	Abstract = {We formulate a new notion of softmax temporal consistency that generalizes the standard hard-max Bellman consistency usually considered in value based reinforcement learning (RL). In particular, we show how softmax consistent action values correspond to optimal policies that maximize entropy regularized expected reward. More importantly, we establish that softmax consistent action values and the optimal policy must satisfy a mutual compatibility property that holds across any state-action subsequence. Based on this observation, we develop a new RL algorithm, Path Consistency Learning (PCL), that minimizes the total inconsistency measured along multi-step subsequences extracted from both both on and off policy traces. An experimental evaluation demonstrates that PCL significantly outperforms strong actor-critic and Q-learning baselines across several benchmark tasks.},
	Author = {Ofir Nachum and Mohammad Norouzi and Kelvin Xu and Dale Schuurmans},
	Date-Added = {2017-03-02 19:27:04 +0000},
	Date-Modified = {2017-03-02 19:27:04 +0000},
	Eprint = {1702.08892},
	Month = {02},
	Title = {Bridging the Gap Between Value and Policy Based Reinforcement Learning},
	Url = {https://arxiv.org/abs/1702.08892},
	Year = {2017},
	Bdsk-Url-1 = {https://arxiv.org/abs/1702.08892}}

@article{amos:20172a,
	Abstract = {This paper presents OptNet, a network architecture that integrates optimization problems (here, specifically in the form of quadratic programs) as individual layers in larger end-to-end trainable deep networks. These layers allow complex dependencies between the hidden states to be captured that traditional convolutional and fully-connected layers are not able to capture. In this paper, we develop the foundations for such an architecture: we derive the equations to perform exact differentiation through these layers and with respect to layer parameters; we develop a highly efficient solver for these layers that exploits fast GPU-based batch solves within a primal-dual interior point method, and which provides backpropagation gradients with virtually no additional cost on top of the solve; and we highlight the application of these approaches in several problems. In one particularly standout example, we show that the method is capable of learning to play Sudoku given just input and output games, with no a priori information about the rules of the game; this task is virtually impossible for other neural network architectures that we have experimented with, and highlights the representation capabilities of our approach.},
	Author = {Brandon Amos and J. Zico Kolter},
	Date-Added = {2017-03-02 19:26:45 +0000},
	Date-Modified = {2017-03-02 19:26:45 +0000},
	Eprint = {1703.00443},
	Month = {03},
	Title = {OptNet: Differentiable Optimization as a Layer in Neural Networks},
	Url = {https://arxiv.org/abs/1703.00443},
	Year = {2017},
	Bdsk-Url-1 = {https://arxiv.org/abs/1703.00443}}

@article{kaiser:20172a,
	Author = {Lukasz Kaiser AND Ofir Nachum AND Aurko Roy AND Samy Bengio},
	Date-Added = {2017-01-06 16:44:57 +0000},
	Date-Modified = {2017-01-06 16:44:57 +0000},
	Journal = {ICLR},
	Title = {Learning to Remember Rare Events},
	Url = {https://openreview.net/pdf?id=SJTQLdqlg},
	Year = {2017},
	Bdsk-Url-1 = {https://openreview.net/pdf?id=SJTQLdqlg}}

@electronic{sung:20172a,
	Author = {Flood Sung},
	Date-Added = {2017-01-04 15:25:06 +0000},
	Date-Modified = {2017-01-04 15:26:49 +0000},
	Lastchecked = {01/04/2017},
	Month = {01},
	Url = {https://github.com/songrotek/Deep-Learning-Papers-Reading-Roadmap},
	Year = {2017},
	Bdsk-Url-1 = {https://github.com/songrotek/Deep-Learning-Papers-Reading-Roadmap}}

@article{atan:20162a,
	Abstract = {This paper proposes a novel approach for constructing effective personalized policies when the observed data lacks counter-factual information, is biased and possesses many features. The approach is applicable in a wide variety of settings from healthcare to advertising to education to finance. These settings have in common that the decision maker can observe, for each previous instance, an array of features of the instance, the action taken in that instance, and the reward realized -- but not the rewards of actions that were not taken: the counterfactual information. Learning in such settings is made even more difficult because the observed data is typically biased by the existing policy (that generated the data) and because the array of features that might affect the reward in a particular instance -- and hence should be taken into account in deciding on an action in each particular instance -- is often vast. The approach presented here estimates propensity scores for the observed data, infers counterfactuals, identifies a (relatively small) number of features that are (most) relevant for each possible action and instance, and prescribes a policy to be followed. Comparison of the proposed algorithm against the state-of-art algorithm on actual datasets demonstrates that the proposed algorithm achieves a significant improvement in performance.},
	Author = {Onur Atan and William R. Zame and Qiaojun Feng and Mihaela van der Schaar},
	Date-Added = {2017-01-04 15:00:20 +0000},
	Date-Modified = {2017-01-04 15:00:20 +0000},
	Eprint = {1612.08082},
	Month = {12},
	Title = {Constructing Effective Personalized Policies Using Counterfactual Inference from Biased Data Sets with Many Features},
	Url = {https://arxiv.org/abs/1612.08082},
	Year = {2016},
	Bdsk-Url-1 = {https://arxiv.org/abs/1612.08082}}

@article{hartford:20162c,
	Abstract = {We are in the middle of a remarkable rise in the use and capability of artificial intelligence. Much of this growth has been fueled by the success of deep learning architectures: models that map from observables to outputs via multiple layers of latent representations. These deep learning algorithms are effective tools for unstructured prediction, and they can be combined in AI systems to solve complex automated reasoning problems. This paper provides a recipe for combining ML algorithms to solve for causal effects in the presence of instrumental variables -- sources of treatment randomization that are conditionally independent from the response. We show that a flexible IV specification resolves into two prediction tasks that can be solved with deep neural nets: a first-stage network for treatment prediction and a second-stage network whose loss function involves integration over the conditional treatment distribution. This Deep IV framework imposes some specific structure on the stochastic gradient descent routine used for training, but it is general enough that we can take advantage of off-the-shelf ML capabilities and avoid extensive algorithm customization. We outline how to obtain out-of-sample causal validation in order to avoid over-fit. We also introduce schemes for both Bayesian and frequentist inference: the former via a novel adaptation of dropout training, and the latter via a data splitting routine.},
	Author = {Jason Hartford and Greg Lewis and Kevin Leyton-Brown and Matt Taddy},
	Date-Added = {2017-01-04 14:54:22 +0000},
	Date-Modified = {2017-01-04 14:54:22 +0000},
	Eprint = {1612.09596},
	Month = {12},
	Title = {Counterfactual Prediction with Deep Instrumental Variables Networks},
	Url = {https://arxiv.org/abs/1612.09596},
	Year = {2016},
	Bdsk-Url-1 = {https://arxiv.org/abs/1612.09596}}

@article{webb1999two,
	Author = {Webb, Roy H and others},
	Date-Added = {2017-01-03 20:32:06 +0000},
	Date-Modified = {2017-01-03 20:32:06 +0000},
	Journal = {Economic Quarterly-Federal Reserve Bank of Richmond},
	Number = {3},
	Pages = {23--40},
	Publisher = {THE FEDERAL RESERVE BANK OF RICHMOND},
	Title = {Two approaches to macroeconomic forecasting},
	Volume = {85},
	Year = {1999}}

@techreport{RePEc:fip:fedawp:2014-07,
	Abstract = {This paper documents GDPNow, a \&quot;nowcasting\&quot; model for gross domestic product (GDP) growth that synthesizes the \&quot;bridge equation\&quot; approach relating GDP subcomponents to monthly source data with the factor model approach used by Giannone, Reichlin, and Small (2008). The GDPNow model forecasts GDP growth by aggregating 13 subcomponents that make up GDP with the chain-weighting methodology used by the U.S. Bureau of Economic Analysis. Using current vintage data, out-of-sample GDPNow model forecasts are found to be more accurate than a number of statistical benchmarks since 2000. Using real-time data since the second-half of 2011, GDPNow model forecasts are found to be only slightly inferior to consensus near-term GDP forecasts from Blue Chip Economic Indicators. The forecast error variance of GDP growth for each of the GDPNow model, Blue Chip, and the Federal Reserve staff's Green Book is decomposed as the sum of the forecast error covariances for the contributions to growth of the subcomponents of GDP. The decompositions show that \&quot;net exports\&quot; and \&quot;change in private inventories\&quot; are particularly difficult subcomponents to nowcast.},
	Author = {Higgins, Patrick C.},
	Date-Added = {2017-01-03 19:50:59 +0000},
	Date-Modified = {2017-01-03 19:52:24 +0000},
	Institution = {Federal Reserve Bank of Atlanta},
	Keywords = {nowcasting; forecasting; macroeconometric forecasting},
	Month = Jul,
	Number = {2014-7},
	Title = {{GDPNow: A Model for GDP ``Nowcasting''}},
	Type = {FRB Atlanta Working Paper},
	Url = {https://ideas.repec.org/p/fip/fedawp/2014-07.html},
	Year = 2014,
	Bdsk-Url-1 = {https://ideas.repec.org/p/fip/fedawp/2014-07.html}}

@article{hartford:20162b,
	Abstract = {We are in the middle of a remarkable rise in the use and capability of artificial intelligence. Much of this growth has been fueled by the success of deep learning architectures: models that map from observables to outputs via multiple layers of latent representations. These deep learning algorithms are effective tools for unstructured prediction, and they can be combined in AI systems to solve complex automated reasoning problems. This paper provides a recipe for combining ML algorithms to solve for causal effects in the presence of instrumental variables -- sources of treatment randomization that are conditionally independent from the response. We show that a flexible IV specification resolves into two prediction tasks that can be solved with deep neural nets: a first-stage network for treatment prediction and a second-stage network whose loss function involves integration over the conditional treatment distribution. This Deep IV framework imposes some specific structure on the stochastic gradient descent routine used for training, but it is general enough that we can take advantage of off-the-shelf ML capabilities and avoid extensive algorithm customization. We outline how to obtain out-of-sample causal validation in order to avoid over-fit. We also introduce schemes for both Bayesian and frequentist inference: the former via a novel adaptation of dropout training, and the latter via a data splitting routine.},
	Author = {Jason Hartford and Greg Lewis and Kevin Leyton-Brown and Matt Taddy},
	Date-Added = {2017-01-03 15:05:02 +0000},
	Date-Modified = {2017-01-03 15:05:02 +0000},
	Eprint = {1612.09596},
	Month = {12},
	Title = {Counterfactual Prediction with Deep Instrumental Variables Networks},
	Url = {https://arxiv.org/abs/1612.09596},
	Year = {2016},
	Bdsk-Url-1 = {https://arxiv.org/abs/1612.09596}}

@inproceedings{hartford:20162a,
	Author = {Hartford, Jason S and Wright, James R and Leyton-Brown, Kevin},
	Booktitle = {Advances in Neural Information Processing Systems},
	Date-Added = {2016-12-30 17:52:35 +0000},
	Date-Modified = {2016-12-30 17:52:55 +0000},
	Pages = {2424--2432},
	Title = {Deep learning for predicting human strategic behavior},
	Url = {http://www.cs.ubc.ca/~jasonhar/GameNet-NIPS-2016.pdf},
	Year = {2016},
	Bdsk-Url-1 = {http://www.cs.ubc.ca/~jasonhar/GameNet-NIPS-2016.pdf}}

@article{heinrich:20162a,
	Abstract = {Many real-world applications can be described as large-scale games of imperfect information. To deal with these challenging domains, prior work has focused on computing Nash equilibria in a handcrafted abstraction of the domain. In this paper we introduce the first scalable end-to-end approach to learning approximate Nash equilibria without prior domain knowledge. Our method combines fictitious self-play with deep reinforcement learning. When applied to Leduc poker, Neural Fictitious Self-Play (NFSP) approached a Nash equilibrium, whereas common reinforcement learning methods diverged. In Limit Texas Holdem, a poker game of real-world scale, NFSP learnt a strategy that approached the performance of state-of-the-art, superhuman algorithms based on significant domain expertise.},
	Author = {Johannes Heinrich and David Silver},
	Date-Added = {2016-12-30 17:50:13 +0000},
	Date-Modified = {2016-12-30 17:50:13 +0000},
	Eprint = {1603.01121},
	Month = {03},
	Title = {Deep Reinforcement Learning from Self-Play in Imperfect-Information Games},
	Url = {https://arxiv.org/abs/1603.01121},
	Year = {2016},
	Bdsk-Url-1 = {https://arxiv.org/abs/1603.01121}}

@article{sukhbaatar:20162a,
	Abstract = {Many tasks in AI require the collaboration of multiple agents. Typically, the communication protocol between agents is manually specified and not altered during training. In this paper we explore a simple neural model, called CommNet, that uses continuous communication for fully cooperative tasks. The model consists of multiple agents and the communication between them is learned alongside their policy. We apply this model to a diverse set of tasks, demonstrating the ability of the agents to learn to communicate amongst themselves, yielding improved performance over non-communicative agents and baselines. In some cases, it is possible to interpret the language devised by the agents, revealing simple but effective strategies for solving the task at hand.},
	Author = {Sainbayar Sukhbaatar and Arthur Szlam and Rob Fergus},
	Date-Added = {2016-12-19 19:37:47 +0000},
	Date-Modified = {2016-12-19 19:37:47 +0000},
	Eprint = {1605.07736},
	Month = {05},
	Title = {Learning Multiagent Communication with Backpropagation},
	Url = {https://arxiv.org/abs/1605.07736},
	Year = {2016},
	Bdsk-Url-1 = {https://arxiv.org/abs/1605.07736}}

@webpage{silver:2a,
	Author = {David Silver},
	Date-Added = {2016-12-16 17:07:12 +0000},
	Date-Modified = {2016-12-16 17:09:34 +0000},
	Lastchecked = {2016-12-16},
	Title = {Reinforcement Learning Lectures},
	Url = {https://youtu.be/2pWv7GOvuf0},
	Bdsk-Url-1 = {https://youtu.be/2pWv7GOvuf0}}

@article{huang:20162a,
	Abstract = {Very deep convolutional networks with hundreds of layers have led to significant reductions in error on competitive benchmarks. Although the unmatched expressiveness of the many layers can be highly desirable at test time, training very deep networks comes with its own set of challenges. The gradients can vanish, the forward flow often diminishes, and the training time can be painfully slow. To address these problems, we propose stochastic depth, a training procedure that enables the seemingly contradictory setup to train short networks and use deep networks at test time. We start with very deep networks but during training, for each mini-batch, randomly drop a subset of layers and bypass them with the identity function. This simple approach complements the recent success of residual networks. It reduces training time substantially and improves the test error significantly on almost all data sets that we used for evaluation. With stochastic depth we can increase the depth of residual networks even beyond 1200 layers and still yield meaningful improvements in test error (4.91% on CIFAR-10).},
	Author = {Gao Huang and Yu Sun and Zhuang Liu and Daniel Sedra and Kilian Weinberger},
	Date-Added = {2016-11-08 15:42:43 +0000},
	Date-Modified = {2016-11-08 15:42:43 +0000},
	Eprint = {1603.09382},
	Month = {03},
	Title = {Deep Networks with Stochastic Depth},
	Url = {https://arxiv.org/abs/1603.09382},
	Year = {2016},
	Bdsk-Url-1 = {https://arxiv.org/abs/1603.09382}}

@book{sutton:19982a,
	Author = {Sutton, Richard S and Barto, Andrew G},
	Date-Added = {2016-12-16 15:39:05 +0000},
	Date-Modified = {2016-12-16 15:39:53 +0000},
	Number = {1},
	Publisher = {MIT press Cambridge},
	Title = {Reinforcement learning: An introduction},
	Url = {https://webdocs.cs.ualberta.ca/~sutton/book/the-book.html},
	Volume = {1},
	Year = {1998},
	Bdsk-Url-1 = {https://webdocs.cs.ualberta.ca/~sutton/book/the-book.html}}

@url{veen:20162a,
	Author = {Fjodor van Veen},
	Date-Added = {2016-12-14 01:12:13 +0000},
	Date-Modified = {2016-12-14 01:12:57 +0000},
	Url = {http://www.asimovinstitute.org/neural-network-zoo/},
	Year = {2016},
	Bdsk-Url-1 = {http://www.asimovinstitute.org/neural-network-zoo/}}

@article{guclu:20142a,
	Author = {Umut G\"{u}\c{c}l\"{u} and Marcel A. J. van Gerven},
	Date-Added = {2016-12-14 00:55:06 +0000},
	Date-Modified = {2016-12-14 00:56:40 +0000},
	Eprint = {1411.6422},
	Month = {11},
	Title = {Deep Neural Networks Reveal a Gradient in the Complexity of Neural Representations across the Brain's Ventral Visual Pathway},
	Url = {https://arxiv.org/abs/1411.6422},
	Year = {2014},
	Bdsk-Url-1 = {https://arxiv.org/abs/1411.6422}}

@inproceedings{deng:20142a,
	Author = {Li Deng and John C. Platt},
	Booktitle = {INTERSPEECH},
	Date-Added = {2016-12-06 20:59:48 +0000},
	Date-Modified = {2016-12-06 20:59:50 +0000},
	Title = {Ensemble deep learning for speech recognition},
	Year = {2014}}

@article{Niaki2013,
	Abstract = {The main objective of this research is to forecast the daily direction of Standard {\&amp;} Poor's 500 (S{\&amp;}P 500) index using an artificial neural network (ANN). In order to select the most influential features (factors) of the proposed ANN that affect the daily direction of S{\&amp;}P 500 (the response), design of experiments are conducted to determine the statistically significant factors among 27 potential financial and economical variables along with a feature defined as the number of nodes of the ANN. The results of employing the proposed methodology show that the ANN that uses the most influential features is able to forecast the daily direction of S{\&amp;}P 500 significantly better than the traditional logit model. Furthermore, experimental results of employing the proposed ANN on the trades in a test period indicate that ANN could significantly improve the trading profit as compared with the buy-and-hold strategy.},
	Author = {Niaki, Seyed Taghi Akhavan and Hoseinzade, Saeid},
	Date-Added = {2016-12-06 20:38:18 +0000},
	Date-Modified = {2016-12-06 20:38:18 +0000},
	Doi = {10.1186/2251-712X-9-1},
	Issn = {2251-712X},
	Journal = {Journal of Industrial Engineering International},
	Number = {1},
	Pages = {1},
	Title = {Forecasting S{\&amp;}P 500 index using artificial neural networks and design of experiments},
	Url = {http://dx.doi.org/10.1186/2251-712X-9-1},
	Volume = {9},
	Year = {2013},
	Bdsk-Url-1 = {http://dx.doi.org/10.1186/2251-712X-9-1}}

@article{heaton:20162a,
	Abstract = {We explore the use of deep learning hierarchical models for problems in financial prediction and classification. Financial prediction problems -- such as those presented in designing and pricing securities, constructing portfolios, and risk management -- often involve large data sets with complex data interactions that currently are difficult or impossible to specify in a full economic model. Applying deep learning methods to these problems can produce more useful results than standard methods in finance. In particular, deep learning can detect and exploit interactions in the data that are, at least currently, invisible to any existing financial economic theory.},
	Author = {J. B. Heaton and N. G. Polson and J. H. Witte},
	Date-Added = {2016-12-06 20:34:09 +0000},
	Date-Modified = {2016-12-06 20:34:09 +0000},
	Eprint = {1602.06561},
	Month = {02},
	Title = {Deep Learning in Finance},
	Url = {https://arxiv.org/abs/1602.06561},
	Year = {2016},
	Bdsk-Url-1 = {https://arxiv.org/abs/1602.06561}}

@article{chung:20142a,
	Abstract = {In this paper we compare different types of recurrent units in recurrent neural networks (RNNs). Especially, we focus on more sophisticated units that implement a gating mechanism, such as a long short-term memory (LSTM) unit and a recently proposed gated recurrent unit (GRU). We evaluate these recurrent units on the tasks of polyphonic music modeling and speech signal modeling. Our experiments revealed that these advanced recurrent units are indeed better than more traditional recurrent units such as tanh units. Also, we found GRU to be comparable to LSTM.},
	Author = {Junyoung Chung and Caglar Gulcehre and KyungHyun Cho and Yoshua Bengio},
	Date-Added = {2016-10-20 15:17:20 +0000},
	Date-Modified = {2016-10-20 15:17:20 +0000},
	Eprint = {1412.3555},
	Month = {12},
	Title = {Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling},
	Url = {https://arxiv.org/abs/1412.3555},
	Year = {2014},
	Bdsk-Url-1 = {https://arxiv.org/abs/1412.3555}}

@article{graves:20142b,
	Abstract = {We extend the capabilities of neural networks by coupling them to external memory resources, which they can interact with by attentional processes. The combined system is analogous to a Turing Machine or Von Neumann architecture but is differentiable end-to-end, allowing it to be efficiently trained with gradient descent. Preliminary results demonstrate that Neural Turing Machines can infer simple algorithms such as copying, sorting, and associative recall from input and output examples.},
	Author = {Alex Graves and Greg Wayne and Ivo Danihelka},
	Date-Added = {2016-10-20 15:16:01 +0000},
	Date-Modified = {2016-10-20 15:16:01 +0000},
	Eprint = {1410.5401},
	Month = {10},
	Title = {Neural Turing Machines},
	Url = {https://arxiv.org/abs/1410.5401},
	Year = {2014},
	Bdsk-Url-1 = {https://arxiv.org/abs/1410.5401}}

@article{graves2016hybrid,
	Author = {Graves, Alex and Wayne, Greg and Reynolds, Malcolm and Harley, Tim and Danihelka, Ivo and Grabska-Barwi{\'n}ska, Agnieszka and Colmenarejo, Sergio G{\'o}mez and Grefenstette, Edward and Ramalho, Tiago and Agapiou, John and others},
	Date-Added = {2016-10-19 19:11:54 +0000},
	Date-Modified = {2016-10-19 19:11:54 +0000},
	Journal = {Nature},
	Publisher = {Nature Research},
	Title = {Hybrid computing using a neural network with dynamic external memory},
	Year = {2016}}

@article{landefeld2008taking,
	Author = {Landefeld, Steven J and Seskin, Eugene P and Fraumeni, Barbara M},
	Date-Added = {2016-10-19 19:06:38 +0000},
	Date-Modified = {2016-10-19 19:06:38 +0000},
	Doi = {10.1257/jep.22.2.193},
	Journal = {The Journal of Economic Perspectives},
	Number = {2},
	Pages = {193--193},
	Publisher = {American Economic Association},
	Title = {Taking the pulse of the economy: Measuring GDP},
	Url = {https://www.aeaweb.org/articles?id=10.1257/jep.22.2.193},
	Volume = {22},
	Year = {2008},
	Bdsk-Url-1 = {https://www.aeaweb.org/articles?id=10.1257/jep.22.2.193}}

@article{andor:20162a,
	Abstract = {We introduce a globally normalized transition-based neural network model that achieves state-of-the-art part-of-speech tagging, dependency parsing and sentence compression results. Our model is a simple feed-forward neural network that operates on a task-specific transition system, yet achieves comparable or better accuracies than recurrent models. We discuss the importance of global as opposed to local normalization: a key insight is that the label bias problem implies that globally normalized models can be strictly more expressive than locally normalized models.},
	Author = {Daniel Andor and Chris Alberti and David Weiss and Aliaksei Severyn and Alessandro Presta and Kuzman Ganchev and Slav Petrov and Michael Collins},
	Date-Added = {2016-10-19 19:04:34 +0000},
	Date-Modified = {2016-10-19 19:04:34 +0000},
	Eprint = {1603.06042},
	Month = {03},
	Title = {Globally Normalized Transition-Based Neural Networks},
	Url = {https://arxiv.org/abs/1603.06042},
	Year = {2016},
	Bdsk-Url-1 = {https://arxiv.org/abs/1603.06042}}

@article{cheng:20162a,
	Abstract = {Generalized linear models with nonlinear feature transformations are widely used for large-scale regression and classification problems with sparse inputs. Memorization of feature interactions through a wide set of cross-product feature transformations are effective and interpretable, while generalization requires more feature engineering effort. With less feature engineering, deep neural networks can generalize better to unseen feature combinations through low-dimensional dense embeddings learned for the sparse features. However, deep neural networks with embeddings can over-generalize and recommend less relevant items when the user-item interactions are sparse and high-rank. In this paper, we present Wide & Deep learning---jointly trained wide linear models and deep neural networks---to combine the benefits of memorization and generalization for recommender systems. We productionized and evaluated the system on Google Play, a commercial mobile app store with over one billion active users and over one million apps. Online experiment results show that Wide & Deep significantly increased app acquisitions compared with wide-only and deep-only models. We have also open-sourced our implementation in TensorFlow.},
	Author = {Heng-Tze Cheng and Levent Koc and Jeremiah Harmsen and Tal Shaked and Tushar Chandra and Hrishi Aradhye and Glen Anderson and Greg Corrado and Wei Chai and Mustafa Ispir and Rohan Anil and Zakaria Haque and Lichan Hong and Vihan Jain and Xiaobing Liu and Hemal Shah},
	Date-Added = {2016-10-19 19:04:24 +0000},
	Date-Modified = {2016-10-19 19:04:24 +0000},
	Eprint = {1606.07792},
	Month = {06},
	Title = {Wide & Deep Learning for Recommender Systems},
	Url = {https://arxiv.org/abs/1606.07792},
	Year = {2016},
	Bdsk-Url-1 = {https://arxiv.org/abs/1606.07792}}

@article{he:20152a,
	Abstract = {Deeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We provide comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers---8x deeper than VGG nets but still having lower complexity. An ensemble of these residual nets achieves 3.57% error on the ImageNet test set. This result won the 1st place on the ILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100 and 1000 layers.},
	Author = {Kaiming He and Xiangyu Zhang and Shaoqing Ren and Jian Sun},
	Date-Added = {2016-10-19 19:04:15 +0000},
	Date-Modified = {2016-10-19 19:04:15 +0000},
	Eprint = {1512.03385},
	Month = {12},
	Title = {Deep Residual Learning for Image Recognition},
	Url = {https://arxiv.org/abs/1512.03385},
	Year = {2015},
	Bdsk-Url-1 = {https://arxiv.org/abs/1512.03385}}

@article{simonyan:20142a,
	Abstract = {In this work we investigate the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting. Our main contribution is a thorough evaluation of networks of increasing depth using an architecture with very small (3x3) convolution filters, which shows that a significant improvement on the prior-art configurations can be achieved by pushing the depth to 16-19 weight layers. These findings were the basis of our ImageNet Challenge 2014 submission, where our team secured the first and the second places in the localisation and classification tracks respectively. We also show that our representations generalise well to other datasets, where they achieve state-of-the-art results. We have made our two best-performing ConvNet models publicly available to facilitate further research on the use of deep visual representations in computer vision.},
	Author = {Karen Simonyan and Andrew Zisserman},
	Date-Added = {2016-10-19 19:04:08 +0000},
	Date-Modified = {2016-10-19 19:04:08 +0000},
	Eprint = {1409.1556},
	Month = {09},
	Title = {Very Deep Convolutional Networks for Large-Scale Image Recognition},
	Url = {https://arxiv.org/abs/1409.1556},
	Year = {2014},
	Bdsk-Url-1 = {https://arxiv.org/abs/1409.1556}}

@article{szegedy:20162a,
	Abstract = {Very deep convolutional networks have been central to the largest advances in image recognition performance in recent years. One example is the Inception architecture that has been shown to achieve very good performance at relatively low computational cost. Recently, the introduction of residual connections in conjunction with a more traditional architecture has yielded state-of-the-art performance in the 2015 ILSVRC challenge; its performance was similar to the latest generation Inception-v3 network. This raises the question of whether there are any benefit in combining the Inception architecture with residual connections. Here we give clear empirical evidence that training with residual connections accelerates the training of Inception networks significantly. There is also some evidence of residual Inception networks outperforming similarly expensive Inception networks without residual connections by a thin margin. We also present several new streamlined architectures for both residual and non-residual Inception networks. These variations improve the single-frame recognition performance on the ILSVRC 2012 classification task significantly. We further demonstrate how proper activation scaling stabilizes the training of very wide residual Inception networks. With an ensemble of three residual and one Inception-v4, we achieve 3.08 percent top-5 error on the test set of the ImageNet classification (CLS) challenge},
	Author = {Christian Szegedy and Sergey Ioffe and Vincent Vanhoucke and Alex Alemi},
	Date-Added = {2016-10-19 19:03:57 +0000},
	Date-Modified = {2016-10-19 19:03:57 +0000},
	Eprint = {1602.07261},
	Month = {02},
	Title = {Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning},
	Url = {https://arxiv.org/abs/1602.07261},
	Year = {2016},
	Bdsk-Url-1 = {https://arxiv.org/abs/1602.07261}}

@article{andrychowicz:20162a,
	Abstract = {The move from hand-designed features to learned features in machine learning has been wildly successful. In spite of this, optimization algorithms are still designed by hand. In this paper we show how the design of an optimization algorithm can be cast as a learning problem, allowing the algorithm to learn to exploit structure in the problems of interest in an automatic way. Our learned algorithms, implemented by LSTMs, outperform generic, hand-designed competitors on the tasks for which they are trained, and also generalize well to new tasks with similar structure. We demonstrate this on a number of tasks, including simple convex problems, training neural networks, and styling images with neural art.},
	Author = {Marcin Andrychowicz and Misha Denil and Sergio Gomez and Matthew W. Hoffman and David Pfau and Tom Schaul and Nando de Freitas},
	Date-Added = {2016-10-19 19:03:42 +0000},
	Date-Modified = {2016-10-19 19:03:42 +0000},
	Eprint = {1606.04474},
	Month = {06},
	Title = {Learning to learn by gradient descent by gradient descent},
	Url = {https://arxiv.org/abs/1606.04474},
	Year = {2016},
	Bdsk-Url-1 = {https://arxiv.org/abs/1606.04474}}

@article{wu:20162a,
	Author = {Yonghui Wu and Mike Schuster and Zhifeng Chen and Quoc V. Le and Mohammad Norouzi and Wolfgang Macherey and Maxim Krikun and Yuan Cao and Qin Gao and Klaus Macherey and Jeff Klingner and Apurva Shah and Melvin Johnson and Xiaobing Liu and {\L}ukasz Kaiser and Stephan Gouws and Yoshikiyo Kato and Taku Kudo and Hideto Kazawa and Keith Stevens and George Kurian and Nishant Patil and Wei Wang and Cliff Young and Jason Smith and Jason Riesa and Alex Rudnick and Oriol Vinyals and Greg Corrado and Macduff Hughes and Jeffrey Dean},
	Date-Added = {2016-10-19 19:03:36 +0000},
	Date-Modified = {2016-12-06 21:06:22 +0000},
	Eprint = {1609.08144},
	Month = {09},
	Title = {Google's Neural Machine Translation System: Bridging the Gap between Human and Machine Translation},
	Url = {https://arxiv.org/abs/1609.08144},
	Year = {2016},
	Bdsk-Url-1 = {https://arxiv.org/abs/1609.08144}}

@article{rezende:20162a,
	Abstract = {Humans have an impressive ability to reason about new concepts and experiences from just a single example. In particular, humans have an ability for one-shot generalization: an ability to encounter a new concept, understand its structure, and then be able to generate compelling alternative variations of the concept. We develop machine learning systems with this important capacity by developing new deep generative models, models that combine the representational power of deep learning with the inferential power of Bayesian reasoning. We develop a class of sequential generative models that are built on the principles of feedback and attention. These two characteristics lead to generative models that are among the state-of-the art in density estimation and image generation. We demonstrate the one-shot generalization ability of our models using three tasks: unconditional sampling, generating new exemplars of a given concept, and generating new exemplars of a family of concepts. In all cases our models are able to generate compelling and diverse samples---having seen new examples just once---providing an important class of general-purpose models for one-shot machine learning.},
	Author = {Danilo Jimenez Rezende and Shakir Mohamed and Ivo Danihelka and Karol Gregor and Daan Wierstra},
	Date-Added = {2016-10-19 19:03:23 +0000},
	Date-Modified = {2016-10-19 19:03:23 +0000},
	Eprint = {1603.05106},
	Month = {03},
	Title = {One-Shot Generalization in Deep Generative Models},
	Url = {https://arxiv.org/abs/1603.05106},
	Year = {2016},
	Bdsk-Url-1 = {https://arxiv.org/abs/1603.05106}}

@article{rusu:20162a,
	Abstract = {Learning to solve complex sequences of tasks--while both leveraging transfer and avoiding catastrophic forgetting--remains a key obstacle to achieving human-level intelligence. The progressive networks approach represents a step forward in this direction: they are immune to forgetting and can leverage prior knowledge via lateral connections to previously learned features. We evaluate this architecture extensively on a wide variety of reinforcement learning tasks (Atari and 3D maze games), and show that it outperforms common baselines based on pretraining and finetuning. Using a novel sensitivity measure, we demonstrate that transfer occurs at both low-level sensory and high-level control layers of the learned policy.},
	Author = {Andrei A. Rusu and Neil C. Rabinowitz and Guillaume Desjardins and Hubert Soyer and James Kirkpatrick and Koray Kavukcuoglu and Razvan Pascanu and Raia Hadsell},
	Date-Added = {2016-10-19 19:02:58 +0000},
	Date-Modified = {2016-10-19 19:02:58 +0000},
	Eprint = {1606.04671},
	Month = {06},
	Title = {Progressive Neural Networks},
	Url = {https://arxiv.org/abs/1606.04671},
	Year = {2016},
	Bdsk-Url-1 = {https://arxiv.org/abs/1606.04671}}

@article{jaderberg:20162a,
	Abstract = {Training directed neural networks typically requires forward-propagating data through a computation graph, followed by backpropagating error signal, to produce weight updates. All layers, or more generally, modules, of the network are therefore locked, in the sense that they must wait for the remainder of the network to execute forwards and propagate error backwards before they can be updated. In this work we break this constraint by decoupling modules by introducing a model of the future computation of the network graph. These models predict what the result of the modelled subgraph will produce using only local information. In particular we focus on modelling error gradients: by using the modelled synthetic gradient in place of true backpropagated error gradients we decouple subgraphs, and can update them independently and asynchronously i.e. we realise decoupled neural interfaces. We show results for feed-forward models, where every layer is trained asynchronously, recurrent neural networks (RNNs) where predicting one's future gradient extends the time over which the RNN can effectively model, and also a hierarchical RNN system with ticking at different timescales. Finally, we demonstrate that in addition to predicting gradients, the same framework can be used to predict inputs, resulting in models which are decoupled in both the forward and backwards pass -- amounting to independent networks which co-learn such that they can be composed into a single functioning corporation.},
	Author = {Max Jaderberg and Wojciech Marian Czarnecki and Simon Osindero and Oriol Vinyals and Alex Graves and Koray Kavukcuoglu},
	Date-Added = {2016-10-19 19:02:47 +0000},
	Date-Modified = {2016-10-19 19:02:47 +0000},
	Eprint = {1608.05343},
	Month = {08},
	Title = {Decoupled Neural Interfaces using Synthetic Gradients},
	Url = {https://arxiv.org/abs/1608.05343},
	Year = {2016},
	Bdsk-Url-1 = {https://arxiv.org/abs/1608.05343}}

@article{osband:20162a,
	Abstract = {Efficient exploration in complex environments remains a major challenge for reinforcement learning. We propose bootstrapped DQN, a simple algorithm that explores in a computationally and statistically efficient manner through use of randomized value functions. Unlike dithering strategies such as epsilon-greedy exploration, bootstrapped DQN carries out temporally-extended (or deep) exploration; this can lead to exponentially faster learning. We demonstrate these benefits in complex stochastic MDPs and in the large-scale Arcade Learning Environment. Bootstrapped DQN substantially improves learning times and performance across most Atari games.},
	Author = {Ian Osband and Charles Blundell and Alexander Pritzel and Benjamin Van Roy},
	Date-Added = {2016-10-19 19:02:38 +0000},
	Date-Modified = {2016-10-19 19:02:38 +0000},
	Eprint = {1602.04621},
	Month = {02},
	Title = {Deep Exploration via Bootstrapped DQN},
	Url = {https://arxiv.org/abs/1602.04621},
	Year = {2016},
	Bdsk-Url-1 = {https://arxiv.org/abs/1602.04621}}

@article{fraccaro:20162a,
	Abstract = {How can we efficiently propagate uncertainty in a latent state representation with recurrent neural networks? This paper introduces stochastic recurrent neural networks which glue a deterministic recurrent neural network and a state space model together to form a stochastic and sequential neural generative model. The clear separation of deterministic and stochastic layers allows a structured variational inference network to track the factorization of the model's posterior distribution. By retaining both the nonlinear recursive structure of a recurrent neural network and averaging over the uncertainty in a latent path, like a state space model, we improve the state of the art results on the Blizzard and TIMIT speech modeling data sets by a large margin, while achieving comparable performances to competing methods on polyphonic music modeling.},
	Author = {Marco Fraccaro and S{\o}ren Kaae S{\o}nderby and Ulrich Paquet and Ole Winther},
	Date-Added = {2016-10-19 19:02:28 +0000},
	Date-Modified = {2016-10-19 19:02:28 +0000},
	Eprint = {1605.07571},
	Month = {05},
	Title = {Sequential Neural Models with Stochastic Layers},
	Url = {https://arxiv.org/abs/1605.07571},
	Year = {2016},
	Bdsk-Url-1 = {https://arxiv.org/abs/1605.07571}}

@article{alexander:20162a,
	Abstract = {We present a novel deep recurrent neural network architecture that learns to build implicit plans in an end-to-end manner by purely interacting with an environment in reinforcement learning setting. The network builds an internal plan, which is continuously updated upon observation of the next input from the environment. It can also partition this internal representation into contiguous sub- sequences by learning for how long the plan can be committed to - i.e. followed without re-planing. Combining these properties, the proposed model, dubbed STRategic Attentive Writer (STRAW) can learn high-level, temporally abstracted macro- actions of varying lengths that are solely learnt from data without any prior information. These macro-actions enable both structured exploration and economic computation. We experimentally demonstrate that STRAW delivers strong improvements on several ATARI games by employing temporally extended planning strategies (e.g. Ms. Pacman and Frostbite). It is at the same time a general algorithm that can be applied on any sequence data. To that end, we also show that when trained on text prediction task, STRAW naturally predicts frequent n-grams (instead of macro-actions), demonstrating the generality of the approach.},
	Author = {Alexander and Vezhnevets and Volodymyr Mnih and John Agapiou and Simon Osindero and Alex Graves and Oriol Vinyals and Koray Kavukcuoglu},
	Date-Added = {2016-10-19 19:02:16 +0000},
	Date-Modified = {2016-10-19 19:02:16 +0000},
	Eprint = {1606.04695},
	Month = {06},
	Title = {Strategic Attentive Writer for Learning Macro-Actions},
	Url = {https://arxiv.org/abs/1606.04695},
	Year = {2016},
	Bdsk-Url-1 = {https://arxiv.org/abs/1606.04695}}

@article{foerster:20162a,
	Abstract = {We consider the problem of multiple agents sensing and acting in environments with the goal of maximising their shared utility. In these environments, agents must learn communication protocols in order to share information that is needed to solve the tasks. By embracing deep neural networks, we are able to demonstrate end-to-end learning of protocols in complex environments inspired by communication riddles and multi-agent computer vision problems with partial observability. We propose two approaches for learning in these domains: Reinforced Inter-Agent Learning (RIAL) and Differentiable Inter-Agent Learning (DIAL). The former uses deep Q-learning, while the latter exploits the fact that, during learning, agents can backpropagate error derivatives through (noisy) communication channels. Hence, this approach uses centralised learning but decentralised execution. Our experiments introduce new environments for studying the learning of communication protocols and present a set of engineering innovations that are essential for success in these domains.},
	Author = {Jakob N. Foerster and Yannis M. Assael and Nando de Freitas and Shimon Whiteson},
	Date-Added = {2016-10-19 19:02:09 +0000},
	Date-Modified = {2016-10-19 19:02:09 +0000},
	Eprint = {1605.06676},
	Month = {05},
	Title = {Learning to Communicate with Deep Multi-Agent Reinforcement Learning},
	Url = {https://arxiv.org/abs/1605.06676},
	Year = {2016},
	Bdsk-Url-1 = {https://arxiv.org/abs/1605.06676}}

@article{mnih2016strategic,
	Author = {Mnih, Volodymyr and Agapiou, John and Osindero, Simon and Graves, Alex and Vinyals, Oriol and Kavukcuoglu, Koray and others},
	Date-Added = {2016-10-19 18:53:36 +0000},
	Date-Modified = {2016-10-19 18:53:45 +0000},
	Journal = {arXiv preprint arXiv:1606.04695},
	Title = {Strategic Attentive Writer for Learning Macro-Actions},
	Url = {https://arxiv.org/abs/1606.04695},
	Year = {2016},
	Bdsk-Url-1 = {https://arxiv.org/abs/1606.04695}}

@article{foerster2016learning,
	Author = {Foerster, Jakob N and Assael, Yannis M and de Freitas, Nando and Whiteson, Shimon},
	Date-Added = {2016-10-19 18:52:48 +0000},
	Date-Modified = {2016-10-19 18:53:06 +0000},
	Journal = {arXiv preprint arXiv:1605.06676},
	Title = {Learning to Communicate with Deep Multi-Agent Reinforcement Learning},
	Url = {https://arxiv.org/abs/1605.06676v2},
	Year = {2016},
	Bdsk-Url-1 = {https://arxiv.org/abs/1605.06676v2}}

@inproceedings{li:20162b,
	Crossref = {li:20162a},
	Date-Added = {2016-10-06 20:42:12 +0000},
	Date-Modified = {2016-10-06 20:43:04 +0000},
	Url = {https://www.youtube.com/playlist?list=PL16j5WbGpaM0_Tj8CRmurZ8Kk1gEBc7fg},
	Year = {2016},
	Bdsk-Url-1 = {https://www.youtube.com/playlist?list=PL16j5WbGpaM0_Tj8CRmurZ8Kk1gEBc7fg}}

@inproceedings{li:20162a,
	Author = {Fei-Fei Li AND Andrej Karpathy AND Justin Johnson},
	Booktitle = {CS231n: Convolutional Neural Networks for Visual Recognition},
	Crossref = {li:20162a},
	Date-Added = {2016-10-06 20:40:08 +0000},
	Date-Modified = {2016-10-06 20:43:15 +0000},
	Title = {CS231n: Convolutional Neural Networks for Visual Recognition},
	Url = {http://cs231n.stanford.edu/},
	Year = {2016},
	Bdsk-Url-1 = {http://cs231n.stanford.edu/}}

@article{dalto:2a,
	Author = {Dalto, Mladen},
	Date-Added = {2016-10-06 19:59:25 +0000},
	Date-Modified = {2016-10-06 20:01:18 +0000},
	Journal = {Rn ($\Theta$1)},
	Number = {2},
	Title = {Deep neural networks for time series prediction with applications in ultra-short-term wind forecasting},
	Url = {https://www.fer.unizg.hr/_download/repository/KDI-Djalto.pdf},
	Volume = {1},
	Bdsk-Url-1 = {https://www.fer.unizg.hr/_download/repository/KDI-Djalto.pdf}}

@inproceedings{yosinski:20142a,
	Author = {Yosinski, Jason and Clune, Jeff and Bengio, Yoshua and Lipson, Hod},
	Booktitle = {Advances in neural information processing systems},
	Date-Added = {2016-10-06 19:57:16 +0000},
	Date-Modified = {2016-10-06 19:57:47 +0000},
	Pages = {3320--3328},
	Title = {How transferable are features in deep neural networks?},
	Url = {https://arxiv.org/abs/1411.1792},
	Year = {2014},
	Bdsk-Url-1 = {https://arxiv.org/abs/1411.1792}}

@inproceedings{zeiler:20102a,
	Author = {Zeiler, Matthew D and Krishnan, Dilip and Taylor, Graham W and Fergus, Rob},
	Booktitle = {Computer Vision and Pattern Recognition (CVPR), 2010 IEEE Conference on},
	Date-Added = {2016-09-30 16:23:31 +0000},
	Date-Modified = {2016-09-30 16:24:47 +0000},
	Organization = {IEEE},
	Pages = {2528--2535},
	Title = {Deconvolutional networks},
	Year = {2010}}

@inproceedings{Zeiler:2010,
	Author = {Zeiler, Matthew D and Krishnan, Dilip and Taylor, Graham W and Fergus, Rob},
	Booktitle = {Computer Vision and Pattern Recognition (CVPR), 2010 IEEE Conference on},
	Date-Added = {2016-09-30 16:22:28 +0000},
	Date-Modified = {2016-09-30 16:23:30 +0000},
	Organization = {IEEE},
	Pages = {2528--2535},
	Title = {Deconvolutional networks},
	Year = {2010}}

@article{Bourlard:1988aa,
	Annote = {foundational article on auto-encoders},
	Author = {Bourlard, Herv{\'e} and Kamp, Yves},
	Date-Added = {2016-09-30 16:21:14 +0000},
	Date-Modified = {2016-09-30 16:22:23 +0000},
	Journal = {Biological cybernetics},
	Number = {4-5},
	Pages = {291--294},
	Publisher = {Springer},
	Title = {Auto-association by multilayer perceptrons and singular value decomposition},
	Volume = {59},
	Year = {1988}}

@manual{:2016aa,
	Author = {Fjodor van Veen},
	Date-Added = {2016-09-30 16:18:18 +0000},
	Date-Modified = {2016-09-30 16:19:27 +0000},
	Lastchecked = {09/30/2016},
	Month = {Sept},
	Title = {A mostly complete chart of neural networks},
	Url = {http://www.asimovinstitute.org/neural-network-zoo/},
	Year = {2016},
	Bdsk-Url-1 = {http://www.asimovinstitute.org/neural-network-zoo/}}

@manual{Stanford:2016aa,
	Author = {Stanford},
	Date-Added = {2016-09-30 16:17:22 +0000},
	Date-Modified = {2016-09-30 16:18:00 +0000},
	Organization = {Stanford},
	Title = {supervised learning tutorial},
	Url = {http://ufldl.stanford.edu/tutorial/},
	Year = {2016},
	Bdsk-Url-1 = {http://ufldl.stanford.edu/tutorial/}}

@webpage{Department:aa,
	Author = {Computer Science Department, Stanford University.},
	Date-Added = {2016-09-27 21:01:27 +0000},
	Date-Modified = {2017-03-02 19:23:33 +0000},
	Title = {Deep Learning},
	Url = {http://ufldl.stanford.edu/},
	Bdsk-Url-1 = {http://ufldl.stanford.edu/}}

@article{kriesel2007brief,
	Author = {Kriesel, David},
	Date-Added = {2016-09-27 16:48:13 +0000},
	Date-Modified = {2016-09-27 21:03:31 +0000},
	Publisher = {Citeseer},
	Title = {A brief Introduction on Neural Networks},
	Url = {http://www.dkriesel.com/_media/science/neuronalenetze-en-zeta2-2col-dkrieselcom.pdf},
	Year = {2007},
	Bdsk-Url-1 = {http://www.dkriesel.com/_media/science/neuronalenetze-en-zeta2-2col-dkrieselcom.pdf}}

@book{gurney1997introduction,
	Author = {Gurney, Kevin},
	Date-Added = {2016-09-27 16:45:23 +0000},
	Date-Modified = {2016-09-27 21:03:56 +0000},
	Publisher = {CRC press},
	Title = {An introduction to neural networks},
	Url = {http://www.inf.ed.ac.uk/teaching/courses/nlu/reading/Gurney_et_al.pdf},
	Year = {1997},
	Bdsk-Url-1 = {http://www.inf.ed.ac.uk/teaching/courses/nlu/reading/Gurney_et_al.pdf}}

@inproceedings{szegedy2015going,
	Author = {Szegedy, Christian and Liu, Wei and Jia, Yangqing and Sermanet, Pierre and Reed, Scott and Anguelov, Dragomir and Erhan, Dumitru and Vanhoucke, Vincent and Rabinovich, Andrew},
	Booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
	Date-Added = {2016-09-27 16:43:57 +0000},
	Date-Modified = {2016-09-27 21:04:11 +0000},
	Pages = {1--9},
	Title = {Going deeper with convolutions},
	Url = {http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Szegedy_Going_Deeper_With_2015_CVPR_paper.pdf},
	Year = {2015},
	Bdsk-Url-1 = {http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Szegedy_Going_Deeper_With_2015_CVPR_paper.pdf}}
